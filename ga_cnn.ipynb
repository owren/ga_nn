{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fe18a62-45bf-4668-b59c-4ba82e8560d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from fashion_mnist_cnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1d8a905-2e63-4b0c-9952-9d5fa0651f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection(pop, fitness, num_parents):\n",
    "    # We select the ones with the highest fitness\n",
    "    sorted_indecies = np.argsort(fitness)[::-1] # we reverse array, because we want ascending\n",
    "    top_indecies = sorted_indecies[:num_parents]\n",
    "    parents = pop[top_indecies]\n",
    "    return parents\n",
    "\n",
    "def crossover(parents, offspring_size):\n",
    "    offspring = np.empty((offspring_size, parents.shape[1]), dtype=np.int)\n",
    "    # The point at which crossover takes place between two parents\n",
    "    crossover_part = int(parents.shape[1]/2)\n",
    "    # Define all the offsprings\n",
    "    for k in range(0, offspring_size, 2):\n",
    "        # we assign random from the two parents\n",
    "        random_choice = np.random.choice(parents.shape[1], crossover_part, replace=False)\n",
    "        gene_selection = np.zeros(parents.shape[1])\n",
    "        gene_selection[random_choice] = 1\n",
    "        # Index of the first parent to mate.\n",
    "        parent1_idx = k%parents.shape[0]\n",
    "        # Index of the second parent to mate.\n",
    "        parent2_idx = (k+1)%parents.shape[0]\n",
    "        # Assign the correct parts of the parents to the offspring\n",
    "        offspring[k, np.where(gene_selection == 0)[0]] = parents[parent1_idx, np.where(gene_selection == 0)[0]]\n",
    "        offspring[k, np.where(gene_selection == 1)[0]] = parents[parent2_idx, np.where(gene_selection == 1)[0]]\n",
    "        offspring[k+1, np.where(gene_selection == 1)[0]] = parents[parent1_idx, np.where(gene_selection == 1)[0]]\n",
    "        offspring[k+1, np.where(gene_selection == 0)[0]] = parents[parent2_idx, np.where(gene_selection == 0)[0]]\n",
    "    return offspring\n",
    "\n",
    "def mutation(offspring_crossover, r_mut=0.2):\n",
    "    # Do if mutation stikes, must be changed if number of options exceed 2\n",
    "    for idx in range(offspring_crossover.shape[0]):\n",
    "        for gene_idx in range(offspring_crossover.shape[1]): \n",
    "            # Flip gene if mutation happens\n",
    "            if (np.random.rand() < r_mut): \n",
    "                offspring_crossover[idx, gene_idx] = 1-offspring_crossover[idx, gene_idx]# bit flip\n",
    "    return offspring_crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "403b1964-c362-480f-ade7-3ff7982b739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The target is to maximize the accuracy of the cnn-mnist model:\n",
    "    We start by having a few decisions related to the model. \n",
    "    // Model hyper-parameters\n",
    "    x1 = (32) or 64 or 128 filters in each CNN layer\n",
    "    x2 = 50 or 100 neurons in first dense layer\n",
    "    x3 = 1 or 2 CNN layers\n",
    "    x4 = he_uniform or random_normal\n",
    "    x5 = no dropout, (0.1 dropout,) 0.2 dropout\n",
    "    x6 = learning rate 0.005, (0.01) or 0.05 \n",
    "    x7 = kernel size cnn (2,) 3, 4\n",
    "    We will use a genetic algorithm to find the best combinations of these hyperparameters. \n",
    "    The fitness-function is based on model accuracy on test-dataset. \n",
    "\"\"\"\n",
    "num_weights = 7\n",
    "# how many options a hyperparameter has\n",
    "options = [2, 2, 2, 2, 2, 2, 2]\n",
    "\n",
    "# solutions per populations and number of mating parents\n",
    "sol_per_pop = 6\n",
    "num_parents = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94d1db0f-dbdb-44e1-9f35-2fe39c4698e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 1 1 1]\n",
      " [1 0 0 0 1 1 0]\n",
      " [1 0 1 1 0 1 0]\n",
      " [0 0 1 0 0 1 1]\n",
      " [0 1 0 0 0 1 0]\n",
      " [1 1 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Defining the population size.\n",
    "pop_size = (sol_per_pop,num_weights) # The population will have sol_per_pop chromosome where each chromosome has num_weights genes.\n",
    "#Creating the initial population.\n",
    "new_population = np.random.randint(low=0, high=2, size=pop_size)\n",
    "print(new_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6b6b778-372d-4ff9-a2a8-db006f5be596",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_outputs = []\n",
    "num_generations = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e14ad95e-064a-433c-9a8c-6adf1ca8a650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation :  0\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 24s 15ms/step - loss: 1.3082 - accuracy: 0.5101 - val_loss: 0.8315 - val_accuracy: 0.6842\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 20s 14ms/step - loss: 0.8427 - accuracy: 0.6809 - val_loss: 0.7573 - val_accuracy: 0.7086\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 20s 14ms/step - loss: 0.7784 - accuracy: 0.7068 - val_loss: 0.7238 - val_accuracy: 0.7239\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 22s 14ms/step - loss: 0.7439 - accuracy: 0.7143 - val_loss: 0.6760 - val_accuracy: 0.7398\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 22s 14ms/step - loss: 0.7221 - accuracy: 0.7234 - val_loss: 0.6786 - val_accuracy: 0.7312\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.7075 - accuracy: 0.7325 - val_loss: 0.6089 - val_accuracy: 0.7584\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.6891 - accuracy: 0.7385 - val_loss: 0.6360 - val_accuracy: 0.7617\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.6904 - accuracy: 0.7368 - val_loss: 0.6190 - val_accuracy: 0.7585\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.6806 - accuracy: 0.7417 - val_loss: 0.6323 - val_accuracy: 0.7433\n",
      "Accuracy pop: > 75.360 [0 1 1 0 1 1 1]\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 23s 15ms/step - loss: 1.4855 - accuracy: 0.4705 - val_loss: 0.8569 - val_accuracy: 0.6720\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 22s 15ms/step - loss: 0.8919 - accuracy: 0.6663 - val_loss: 0.8564 - val_accuracy: 0.6788\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 22s 15ms/step - loss: 0.8434 - accuracy: 0.6883 - val_loss: 0.7607 - val_accuracy: 0.7138\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 23s 15ms/step - loss: 0.7982 - accuracy: 0.7000 - val_loss: 0.7809 - val_accuracy: 0.7042\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 22s 15ms/step - loss: 0.7997 - accuracy: 0.7040 - val_loss: 0.7396 - val_accuracy: 0.7183\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 22s 15ms/step - loss: 0.7811 - accuracy: 0.7095 - val_loss: 0.8095 - val_accuracy: 0.6970\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 22s 15ms/step - loss: 0.7764 - accuracy: 0.7165 - val_loss: 0.7187 - val_accuracy: 0.7333\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 22s 15ms/step - loss: 0.7686 - accuracy: 0.7149 - val_loss: 0.7035 - val_accuracy: 0.7384\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 22s 15ms/step - loss: 0.7535 - accuracy: 0.7229 - val_loss: 0.6934 - val_accuracy: 0.7369\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 22s 15ms/step - loss: 0.7378 - accuracy: 0.7278 - val_loss: 0.6744 - val_accuracy: 0.7507\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 23s 15ms/step - loss: 0.7346 - accuracy: 0.7293 - val_loss: 0.7608 - val_accuracy: 0.7243\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 23s 15ms/step - loss: 0.7404 - accuracy: 0.7268 - val_loss: 0.7442 - val_accuracy: 0.7271\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 22s 15ms/step - loss: 0.7539 - accuracy: 0.7196 - val_loss: 0.7494 - val_accuracy: 0.7259\n",
      "Accuracy pop: > 76.860 [1 0 0 0 1 1 0]\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 25s 16ms/step - loss: 1.2571 - accuracy: 0.5285 - val_loss: 0.7673 - val_accuracy: 0.7067\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 24s 16ms/step - loss: 0.7541 - accuracy: 0.7157 - val_loss: 0.7017 - val_accuracy: 0.7367\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 24s 16ms/step - loss: 0.7037 - accuracy: 0.7318 - val_loss: 0.6708 - val_accuracy: 0.7442\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 24s 16ms/step - loss: 0.6616 - accuracy: 0.7500 - val_loss: 0.6375 - val_accuracy: 0.7620\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 24s 16ms/step - loss: 0.6388 - accuracy: 0.7591 - val_loss: 0.6303 - val_accuracy: 0.7552\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 24s 16ms/step - loss: 0.6289 - accuracy: 0.7610 - val_loss: 0.5988 - val_accuracy: 0.7655\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 24s 16ms/step - loss: 0.6103 - accuracy: 0.7676 - val_loss: 0.5909 - val_accuracy: 0.7763\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 24s 16ms/step - loss: 0.6047 - accuracy: 0.7719 - val_loss: 0.6194 - val_accuracy: 0.7705\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 24s 16ms/step - loss: 0.6055 - accuracy: 0.7702 - val_loss: 0.5518 - val_accuracy: 0.7893\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 24s 16ms/step - loss: 0.5943 - accuracy: 0.7767 - val_loss: 0.5685 - val_accuracy: 0.7822\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 24s 16ms/step - loss: 0.6033 - accuracy: 0.7731 - val_loss: 0.5957 - val_accuracy: 0.7731\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 24s 16ms/step - loss: 0.5961 - accuracy: 0.7736 - val_loss: 0.6296 - val_accuracy: 0.7722\n",
      "Accuracy pop: > 79.720 [1 0 1 1 0 1 0]\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 22s 14ms/step - loss: 1.3076 - accuracy: 0.5100 - val_loss: 0.7880 - val_accuracy: 0.7034\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.8057 - accuracy: 0.6954 - val_loss: 0.6942 - val_accuracy: 0.7259\n",
      "Epoch 3/30\n",
      "1496/1500 [============================>.] - ETA: 0s - loss: 0.7247 - accuracy: 0.7246"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a94563d5683a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Generation : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgeneration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Measuring the fitness of each chromosome in the population.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mfitness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_model_ga\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_population\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fitness\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfitness\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\git_repos\\ga_nn\\fashion_mnist_cnn.py\u001b[0m in \u001b[0;36mevaluate_model_ga\u001b[1;34m(pop)\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[0mcallback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;31m# fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             model.fit(datagen.flow(trainX, trainY, batch_size=32,subset='training'), \n\u001b[0m\u001b[0;32m    104\u001b[0m                       \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'validation'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                       epochs=30,callbacks=[callback], verbose=1)\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1129\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1131\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1132\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1387\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1390\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    860\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for generation in range(num_generations):\n",
    "    print(\"Generation : \", generation)\n",
    "    # Measuring the fitness of each chromosome in the population.\n",
    "    fitness = evaluate_model_ga(new_population)\n",
    "    print(\"Fitness\")\n",
    "    print(fitness)\n",
    "    \n",
    "    # Find best result from gen x\n",
    "    generation_best = (np.max(fitness), new_population[np.where(fitness == np.max(fitness))[0]])\n",
    "    best_outputs.append(generation_best)\n",
    "    # The best result in the current iteration.\n",
    "    print(\"Best result : \", generation_best)\n",
    "    \n",
    "    # Selecting the best parents in the population for mating.\n",
    "    parents = selection(new_population, fitness, num_parents)\n",
    "    print(\"Parents\")\n",
    "    print(parents)\n",
    "\n",
    "    # Generating next generation using crossover.\n",
    "    offspring_crossover = crossover(parents, sol_per_pop)\n",
    "    print(\"Crossover\")\n",
    "    print(offspring_crossover)\n",
    "\n",
    "    # Adding some variations to the offspring using mutation.\n",
    "    offspring_mutation = mutation(offspring_crossover, r_mut=0.2)\n",
    "    print(\"Mutation\")\n",
    "    print(offspring_mutation)\n",
    "\n",
    "    # Creating the new population based on the parents and offspring.\n",
    "    new_population = offspring_mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78312634-10aa-45d7-bd92-64850af3db66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3619dd6c-b489-40dc-8836-943aff0fc73d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3293df6-305f-4a77-bd99-e4f182708cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
